# RunPod μ—…λ΅λ“ μ²΄ν¬λ¦¬μ¤νΈ

μ΄ μ²΄ν¬λ¦¬μ¤νΈλ¥Ό λ”°λΌ RunPodμ— μ—…λ΅λ“ν•  νμΌλ“¤μ„ μ¤€λΉ„ν•μ„Έμ”.

## π“ ν•„μ νμΌ λ©λ΅

### β… ν•µμ‹¬ μ¤ν¬λ¦½νΈ
- [ ] `train.py` - νμΈνλ‹ λ©”μΈ μ¤ν¬λ¦½νΈ
- [ ] `config.py` - μ„¤μ • νμΌ (μμ •λ¨: eval_strategy, κ³µκ° λ¨λΈ, λ©”λ¨λ¦¬ μµμ ν™”)
- [ ] `data_preprocessing.py` - λ°μ΄ν„° μ „μ²λ¦¬
- [ ] `evaluate.py` - ν‰κ°€ μ¤ν¬λ¦½νΈ
- [ ] `inference.py` - μ¶”λ΅  μ¤ν¬λ¦½νΈ
- [ ] `runpod_setup.py` - RunPod ν™κ²½ μ„¤μ • (μ—…λ°μ΄νΈλ¨)

### β… μ„¤μ • λ° μμ΅΄μ„±
- [ ] `requirements.txt` - μμ΅΄μ„± λ©λ΅ (μ—…λ°μ΄νΈλ¨)
- [ ] `finetuning_notebook.ipynb` - Jupyter λ…ΈνΈλ¶

### β… λ°μ΄ν„° νμΌ
- [ ] `generated_dataset.jsonl` - ν•™μµ λ°μ΄ν„° (μ¤‘μ”!)

### β… λ¬Έμ„
- [ ] `README.md` - ν”„λ΅μ νΈ μ„¤λ… (μ—…λ°μ΄νΈλ¨)
- [ ] `RUNPOD_GUIDE.md` - RunPod μƒμ„Έ κ°€μ΄λ“ (μ—…λ°μ΄νΈλ¨)
- [ ] `UPLOAD_CHECKLIST.md` - μ΄ νμΌ

## π”§ μμ •λ λ‚΄μ© ν™•μΈ

### 1. config.py μμ •μ‚¬ν•­
- [ ] `evaluation_strategy` β†’ `eval_strategy` λ³€κ²½
- [ ] `model_name` β†’ `"mistralai/Mistral-7B-v0.1"` (κ³µκ° λ¨λΈ)
- [ ] `per_device_train_batch_size` β†’ `2` (λ©”λ¨λ¦¬ μµμ ν™”)
- [ ] `per_device_eval_batch_size` β†’ `2` (λ©”λ¨λ¦¬ μµμ ν™”)
- [ ] `gradient_accumulation_steps` β†’ `8` (μ‹¤μ  λ°°μΉ ν¬κΈ° 16 μ μ§€)
- [ ] `max_seq_length` β†’ `1024` (μ‹¤μ  λ°μ΄ν„° μµλ€ 39 ν† ν°)
- [ ] `dataloader_num_workers` β†’ `0` (λ©”λ¨λ¦¬ μ μ•½)

### 2. train.py μμ •μ‚¬ν•­
- [ ] `evaluation_strategy` β†’ `eval_strategy` λ³€κ²½
- [ ] `gradient_checkpointing=True` μ¶”κ°€ (λ©”λ¨λ¦¬ μµμ ν™”)

### 3. requirements.txt μμ •μ‚¬ν•­
- [ ] λ¨λ“  μμ΅΄μ„± ν¬ν•¨
- [ ] μ£Όμ„ μ¶”κ°€λ΅ κ°€λ…μ„± ν–¥μƒ

### 4. runpod_setup.py μμ •μ‚¬ν•­
- [ ] μ‹μ¤ν… μμ΅΄μ„± μ„¤μΉ (tmux)
- [ ] Hugging Face μΈμ¦ μ„¤μ •
- [ ] ν™κ²½ λ³€μ μ„¤μ •
- [ ] λ¨λ“  λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ

## π“¦ μ—…λ΅λ“ μ¤€λΉ„

### 1. νμΌ κµ¬μ΅° ν™•μΈ
```
mistral_finetuning/
β”β”€β”€ train.py
β”β”€β”€ config.py
β”β”€β”€ data_preprocessing.py
β”β”€β”€ evaluate.py
β”β”€β”€ inference.py
β”β”€β”€ runpod_setup.py
β”β”€β”€ requirements.txt
β”β”€β”€ finetuning_notebook.ipynb
β”β”€β”€ README.md
β”β”€β”€ RUNPOD_GUIDE.md
β”β”€β”€ UPLOAD_CHECKLIST.md
β””β”€β”€ generated_dataset.jsonl
```

### 2. νμΌ ν¬κΈ° ν™•μΈ
- [ ] `generated_dataset.jsonl`: μ•½ 3MB (10,000κ° μƒν”)
- [ ] μ „μ²΄ ν”„λ΅μ νΈ: μ•½ 5-10MB

### 3. μ••μ¶• μ¤€λΉ„
```bash
# λ΅μ»¬μ—μ„ μ••μ¶•
tar -czf mistral_finetuning.tar.gz mistral_finetuning/

# λλ” ZIP
zip -r mistral_finetuning.zip mistral_finetuning/
```

## π€ RunPod μ‹¤ν–‰ μμ„

### 1. Pod μƒμ„±
- [ ] GPU: RTX L40 (48GB VRAM) λλ” RTX 4090 (24GB VRAM)
- [ ] ν…ν”λ¦Ώ: PyTorch 2.0
- [ ] μ¤ν† λ¦¬μ§€: 50GB

### 2. νμΌ μ—…λ΅λ“
- [ ] Jupyter Lab νμΌ λΈλΌμ°μ € μ‚¬μ©
- [ ] λλ” Git ν΄λ΅ 
- [ ] λλ” μ§μ ‘ μ—…λ΅λ“

### 3. ν™κ²½ μ„¤μ •
```bash
cd mistral_finetuning
python runpod_setup.py
```

### 4. λ©”λ¨λ¦¬ μµμ ν™” μ„¤μ •
```bash
# ν™κ²½ λ³€μ μ„¤μ •
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export TOKENIZERS_PARALLELISM=false

# λ©”λ¨λ¦¬ μ •λ¦¬
python -c "import torch; torch.cuda.empty_cache()"
```

### 5. νμΈνλ‹ μ‹¤ν–‰
```bash
# tmux μ„Έμ…μ—μ„ μ‹¤ν–‰
tmux new -s finetuning
python train.py
```

### 6. λ¨λ‹ν„°λ§
```bash
# μƒ ν„°λ―Έλ„μ—μ„
watch -n 1 nvidia-smi
tail -f training.log
```

## β οΈ μ£Όμμ‚¬ν•­

### 1. νΈν™μ„± λ¬Έμ  ν•΄κ²°
- [ ] `evaluation_strategy` β†’ `eval_strategy` λ³€κ²½ μ™„λ£
- [ ] κ³µκ° λ¨λΈ μ‚¬μ©μΌλ΅ μΈμ¦ λ¬Έμ  ν•΄κ²°
- [ ] λ¨λ“  μμ΅΄μ„± ν¬ν•¨

### 2. λ©”λ¨λ¦¬ μµμ ν™”
- [ ] `PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True` μ„¤μ •
- [ ] `TOKENIZERS_PARALLELISM=false` μ„¤μ •
- [ ] λ°°μΉ ν¬κΈ° 2, κ·Έλλ””μ–ΈνΈ λ„μ  8 μ„¤μ •
- [ ] μ‹ν€€μ¤ κΈΈμ΄ 1024 μ„¤μ • (μ‹¤μ  λ°μ΄ν„° μµλ€ 39 ν† ν°)
- [ ] κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν… ν™μ„±ν™”

### 3. ν™κ²½ μ„¤μ •
- [ ] tmux μ„¤μΉ
- [ ] Hugging Face μΈμ¦ μ„¤μ •

### 4. λ¨λ‹ν„°λ§
- [ ] GPU μ‚¬μ©λ¥  ν™•μΈ (80-90%)
- [ ] μ²΄ν¬ν¬μΈνΈ μƒμ„± ν™•μΈ
- [ ] λ΅κ·Έ μ‹¤μ‹κ°„ ν™•μΈ

## π“‹ μµμΆ… ν™•μΈ

### μ—…λ΅λ“ μ „
- [ ] λ¨λ“  νμΌμ΄ ν¬ν•¨λμ—λ”μ§€ ν™•μΈ
- [ ] μμ •μ‚¬ν•­μ΄ λ°μλμ—λ”μ§€ ν™•μΈ
- [ ] νμΌ ν¬κΈ°κ°€ μ μ ν•μ§€ ν™•μΈ

### RunPodμ—μ„
- [ ] νμΌ μ—…λ΅λ“ μ™„λ£
- [ ] ν™κ²½ μ„¤μ • μ„±κ³µ
- [ ] λ©”λ¨λ¦¬ μµμ ν™” μ„¤μ • μ™„λ£
- [ ] νμΈνλ‹ μ‹μ‘ μ„±κ³µ
- [ ] GPU μ‚¬μ©λ¥  μ •μƒ

## π― μ„±κ³µ μ§€ν‘

### ν™κ²½ μ„¤μ • μ„±κ³µ
- β… GPU ν™κ²½ ν™•μΈ
- β… λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ μ™„λ£
- β… λ°μ΄ν„° μ „μ²λ¦¬ μ™„λ£
- β… λ©”λ¨λ¦¬ μµμ ν™” μ„¤μ • μ™„λ£

### νμΈνλ‹ μ„±κ³µ
- β… λ¨λΈ λ΅λ”© μ™„λ£
- β… LoRA μ„¤μ • μ™„λ£
- β… ν•™μµ μ‹μ‘
- β… GPU μ‚¬μ©λ¥  80-90%
- β… λ©”λ¨λ¦¬ λ¶€μ΅± μ—†μ

### μ™„λ£ μ§€ν‘
- β… μ²΄ν¬ν¬μΈνΈ μƒμ„±
- β… μ†μ‹¤κ°’ κ°μ†
- β… ν•™μµ μ™„λ£

## π”§ λ©”λ¨λ¦¬ μµμ ν™” μ„¤μ • ν™•μΈ

### ν„μ¬ μµμ ν™”λ μ„¤μ •
- **λ°°μΉ ν¬κΈ°**: 2 (λ©”λ¨λ¦¬ μ μ•½)
- **κ·Έλλ””μ–ΈνΈ λ„μ **: 8 (μ‹¤μ  λ°°μΉ ν¬κΈ° 16 μ μ§€)
- **μ‹ν€€μ¤ κΈΈμ΄**: 1024 (μ‹¤μ  λ°μ΄ν„° μµλ€ 39 ν† ν°)
- **μ›μ»¤ μ**: 0 (λ©”λ¨λ¦¬ μ μ•½)
- **κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν…**: ν™μ„±ν™”

### ν™κ²½ λ³€μ μ„¤μ •
```bash
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export TOKENIZERS_PARALLELISM=false
```

### μμƒ λ©”λ¨λ¦¬ μ‚¬μ©λ‰
- **κΈ°μ΅΄**: 26GB (λ©”λ¨λ¦¬ λ¶€μ΅±)
- **μµμ ν™” ν›„**: 20-22GB (μ•μ „ν• λ²”μ„)

---

**μ΄ μ²΄ν¬λ¦¬μ¤νΈλ¥Ό λ”°λΌν•λ©΄ RunPodμ—μ„ μ•μ •μ μΌλ΅ νμΈνλ‹μ„ μ™„λ£ν•  μ μμµλ‹λ‹¤!** π€