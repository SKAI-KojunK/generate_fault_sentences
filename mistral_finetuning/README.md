# Mistral-7B Fine-tuning Project

μ΄ ν”„λ΅μ νΈλ” Mistral-7B λ¨λΈμ„ μ‚¬μ©ν•μ—¬ μ μ§€λ³΄μ λ°μ΄ν„° νμ‹±μ„ μ„ν• νμΈνλ‹μ„ μν–‰ν•©λ‹λ‹¤.

## π€ λΉ λ¥Έ μ‹μ‘

**π“– μµμ‹  κ°€μ΄λ“**: [RUNPOD_QUICKSTART.md](../RUNPOD_QUICKSTART.md) - **κ°€μ¥ κ°„λ‹¨ν• μ‹¤ν–‰ λ°©λ²•**

### RunPodμ—μ„ μ‹¤ν–‰ (κ¶μ¥)

```bash
# 1. ν”„λ΅μ νΈ μ—…λ΅λ“ ν›„
cd /workspace/generate_fault_sentences

# 2. HF ν† ν° μ„¤μ • (.env νμΌ)
cp .env.example .env
# .env νμΌμ— μ‹¤μ  ν† ν° μ…λ ¥

# 3. μ›μƒ· μ„¤μ • (μ„¤μΉ+μ „μ²λ¦¬)
python mistral_finetuning/runpod_setup.py

# 4. νμΈνλ‹ μ‹¤ν–‰
python mistral_finetuning/run_training.py --epochs 3 --batch_size 4
```

μμ„Έν• λ‚΄μ©μ€ [RUNPOD_QUICKSTART.md](../RUNPOD_QUICKSTART.md)λ¥Ό μ°Έμ΅°ν•μ„Έμ”.

### λ΅μ»¬μ—μ„ μ‹¤ν–‰

1. **μμ΅΄μ„± μ„¤μΉ**
   ```bash
   pip install -r requirements.txt
   ```

2. **λ°μ΄ν„° μ¤€λΉ„**
   ```bash
   python data_preprocessing.py
   ```

3. **νμΈνλ‹ μ‹¤ν–‰**
   ```bash
   python train.py
   ```

## π“ ν”„λ΅μ νΈ κµ¬μ΅°

```
mistral_finetuning/
β”β”€β”€ train.py                    # νμΈνλ‹ λ©”μΈ μ¤ν¬λ¦½νΈ
β”β”€β”€ config.py                   # μ„¤μ • νμΌ (RunPod μµμ ν™” ν¬ν•¨)
β”β”€β”€ data_preprocessing.py       # λ°μ΄ν„° μ „μ²λ¦¬
β”β”€β”€ evaluate.py                 # ν‰κ°€ μ¤ν¬λ¦½νΈ
β”β”€β”€ inference.py                # μ¶”λ΅  μ¤ν¬λ¦½νΈ
β”β”€β”€ runpod_setup.py            # RunPod ν™κ²½ μ„¤μ •
β”β”€β”€ requirements.txt            # μμ΅΄μ„± λ©λ΅
β”β”€β”€ finetuning_notebook.ipynb   # Jupyter λ…ΈνΈλ¶
β”β”€β”€ RUNPOD_GUIDE.md            # RunPod μƒμ„Έ κ°€μ΄λ“
β””β”€β”€ generated_dataset.jsonl     # ν•™μµ λ°μ΄ν„°
```

## β™οΈ μ„¤μ •

### λ¨λΈ μ„¤μ •
- **κΈ°λ³Έ λ¨λΈ**: `mistralai/Mistral-7B-v0.1` (κ³µκ° λ¨λΈ)
- **νμΈνλ‹ λ°©λ²•**: LoRA (Low-Rank Adaptation)
- **μ–‘μν™”**: 4λΉ„νΈ QLoRA

### ν•™μµ μ„¤μ • (RunPod μµμ ν™”)
- **λ°°μΉ ν¬κΈ°**: 2 (λ©”λ¨λ¦¬ μµμ ν™”)
- **κ·Έλλ””μ–ΈνΈ λ„μ **: 8 (μ‹¤μ  λ°°μΉ ν¬κΈ° 16 μ μ§€)
- **μ‹ν€€μ¤ κΈΈμ΄**: 1024 (μ‹¤μ  λ°μ΄ν„° μµλ€ 39 ν† ν°)
- **ν•™μµλ¥ **: 2e-4
- **μ—ν¬ν¬**: 3

### λ©”λ¨λ¦¬ μµμ ν™” μ„¤μ •
- **κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν…**: ν™μ„±ν™”
- **λ°μ΄ν„°λ΅λ” μ›μ»¤**: 0 (λ©”λ¨λ¦¬ μ μ•½)
- **μ‹ν€€μ¤ κΈΈμ΄**: 1024 (μ‹¤μ  λ°μ΄ν„° λ€λΉ„ 26λ°° μ—¬μ )

## π”§ μ£Όμ” κΈ°λ¥

### 1. μλ™ ν™κ²½ μ„¤μ •
```bash
python runpod_setup.py
```
- GPU ν™κ²½ ν™•μΈ
- ν•„μ”ν• λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ
- Hugging Face μΈμ¦ μ„¤μ •
- λ””λ ‰ν† λ¦¬ μƒμ„±
- λ°μ΄ν„° μ „μ²λ¦¬

### 2. νμΈνλ‹ μ‹¤ν–‰
```bash
python train.py
```
- LoRA μ„¤μ •
- λ°μ΄ν„°μ…‹ λ΅λ”©
- ν•™μµ μ‹¤ν–‰
- μ²΄ν¬ν¬μΈνΈ μ €μ¥

### 3. λ¨λΈ ν‰κ°€
```bash
python evaluate.py --model_path checkpoints/best
```

### 4. μ¶”λ΅  ν…μ¤νΈ
```bash
python inference.py --model_path checkpoints/best
```

## π“ λ¨λ‹ν„°λ§

### μ‹¤μ‹κ°„ λ¨λ‹ν„°λ§
```bash
# GPU μ‚¬μ©λ‰
watch -n 1 nvidia-smi

# ν•™μµ λ΅κ·Έ
tail -f training.log

# μ²΄ν¬ν¬μΈνΈ ν™•μΈ
watch -n 10 ls -la checkpoints/
```

### tmux μ„Έμ… κ΄€λ¦¬
```bash
# μ„Έμ… μ‹μ‘
tmux new -s finetuning

# μ„Έμ… μ¬μ—°κ²°
tmux attach -t finetuning

# μ„Έμ… λ©λ΅
tmux list-sessions
```

## π› οΈ λ¬Έμ  ν•΄κ²°

### μΌλ°μ μΈ λ¬Έμ λ“¤

1. **CUDA λ©”λ¨λ¦¬ λ¶€μ΅±**
   ```bash
   # ν™κ²½ λ³€μ μ„¤μ •
   export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
   export TOKENIZERS_PARALLELISM=false
   
   # λ©”λ¨λ¦¬ μ •λ¦¬
   python -c "import torch; torch.cuda.empty_cache()"
   ```

2. **Hugging Face μΈμ¦ μ¤λ¥**
   ```bash
   # κ³µκ° λ¨λΈ μ‚¬μ© (κ¶μ¥)
   # λλ” ν† ν° μ„¤μ •
   export HUGGING_FACE_HUB_TOKEN=your_token
   ```

3. **ν† ν¬λ‚μ΄μ € κ²½κ³ **
   ```bash
   export TOKENIZERS_PARALLELISM=false
   ```

4. **λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ μ¤λ¥**
   ```bash
   pip install --upgrade pip
   pip install --no-cache-dir -r requirements.txt
   ```

## π“ μ„±λ¥ μµμ ν™”

### GPU λ©”λ¨λ¦¬ μµμ ν™”
- 4λΉ„νΈ μ–‘μν™” (QLoRA)
- κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν…
- λ°°μΉ ν¬κΈ° μ΅°μ • (2)
- μ‹ν€€μ¤ κΈΈμ΄ μµμ ν™” (1024)

### ν•™μµ μ†λ„ μµμ ν™”
- LoRA νμΈλ―Έν„°: 0.5754%λ§ ν›λ ¨
- κ·Έλλ””μ–ΈνΈ λ„μ  (8)
- λ©”λ¨λ¦¬ ν¨μ¨μ μΈ μ„¤μ •

## π’° λΉ„μ© μµμ ν™” (RunPod)

1. **ν•™μµ μ™„λ£ ν›„ μ¦‰μ‹ Pod μΆ…λ£**
2. **ν•„μ”μ‹ μ¤λƒ…μƒ· μ €μ¥**
3. **μ μ ν• GPU μ„ νƒ** (L40 vs 4090)

## π“‹ μ²΄ν¬λ¦¬μ¤νΈ

### μ‚¬μ „ μ¤€λΉ„
- [ ] RunPod κ³„μ • μƒμ„±
- [ ] GPU Pod μƒμ„±
- [ ] ν”„λ΅μ νΈ νμΌ μ¤€λΉ„
- [ ] λ°μ΄ν„° νμΌ μ¤€λΉ„

### ν™κ²½ μ„¤μ •
- [ ] νμΌ μ—…λ΅λ“ μ™„λ£
- [ ] `python runpod_setup.py` μ‹¤ν–‰
- [ ] GPU ν™κ²½ ν™•μΈ
- [ ] λΌμ΄λΈλ¬λ¦¬ μ„¤μΉ μ™„λ£

### νμΈνλ‹ μ‹¤ν–‰
- [ ] tmux μ„Έμ… μ‹μ‘
- [ ] `python train.py` μ‹¤ν–‰
- [ ] GPU μ‚¬μ©λ¥  ν™•μΈ (80-90%)
- [ ] μ²΄ν¬ν¬μΈνΈ μƒμ„± ν™•μΈ

## π“ μ§€μ›

- **RunPod κ°€μ΄λ“**: [RUNPOD_GUIDE.md](RUNPOD_GUIDE.md)
- **λ¬Έμ  ν•΄κ²°**: μ΄ READMEμ λ¬Έμ  ν•΄κ²° μ„Ήμ…
- **GitHub Issues**: ν”„λ΅μ νΈ μ €μ¥μ†

## β±οΈ μμƒ μ†μ” μ‹κ°„

- **ν™κ²½ μ„¤μ •**: 10-15λ¶„
- **λ¨λΈ λ‹¤μ΄λ΅λ“**: 5-10λ¶„
- **νμΈνλ‹**: 2-3μ‹κ°„ (L40), 3-4μ‹κ°„ (4090)
- **κ²°κ³Ό μ²λ¦¬**: 5-10λ¶„

## π”§ RunPod μµμ ν™” μ‚¬ν•­

### λ©”λ¨λ¦¬ μµμ ν™”
- **λ°°μΉ ν¬κΈ°**: 4 β†’ 2 (50% λ©”λ¨λ¦¬ μ μ•½)
- **κ·Έλλ””μ–ΈνΈ λ„μ **: 4 β†’ 8 (μ‹¤μ  λ°°μΉ ν¬κΈ° 16 μ μ§€)
- **μ‹ν€€μ¤ κΈΈμ΄**: 2048 β†’ 1024 (μ‹¤μ  λ°μ΄ν„° μµλ€ 39 ν† ν°)
- **μ›μ»¤ μ**: 4 β†’ 0 (λ©”λ¨λ¦¬ μ μ•½)
- **κ·Έλλ””μ–ΈνΈ μ²΄ν¬ν¬μΈν…**: ν™μ„±ν™”

### νΈν™μ„± μμ •
- **evaluation_strategy** β†’ **eval_strategy**
- **κ³µκ° λ¨λΈ μ‚¬μ©**: μΈμ¦ λ¶ν•„μ”
- **ν™κ²½ λ³€μ μ„¤μ •**: λ©”λ¨λ¦¬ λ‹¨νΈν™” λ°©μ§€

---

**μ΄ ν”„λ΅μ νΈλ” RunPodμ—μ„ μ•μ •μ μΌλ΅ μ‹¤ν–‰λλ„λ΅ μµμ ν™”λμ—μµλ‹λ‹¤!** π€ 